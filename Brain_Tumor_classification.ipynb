{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_UoR8kzvc8p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/New.zip\"\n",
        "extract_dir = \"/content/New\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "os.listdir(extract_dir)"
      ],
      "metadata": {
        "id": "2XHOL8L_w6yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import cv2\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import  BatchNormalization\n",
        "import numpy as np\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "qSCglmUGw84A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir= '/content/New/New'\n",
        "total_image=3064\n",
        "datalist=[]\n",
        "for i in range(1,total_image+1):\n",
        "  filename=str(i)+\".mat\"\n",
        "  data=h5py.File(os.path.join(data_dir,filename),\"r\")\n",
        "  datalist.append(data)\n",
        "\n",
        "  if i%100==0:\n",
        "    print(filename)"
      ],
      "metadata": {
        "id": "5z_PaE6Uw_Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=[]\n",
        "\n",
        "\n",
        "for i  in range(total_image):\n",
        "  lb=int(datalist[i][\"cjdata\"][\"label\"][()])-1\n",
        "\n",
        "  labels.append(lb)\n",
        "\n",
        "labels=np.array(labels)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "uYw1x74pxBNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "integer_to_class = {'0': 'meningioma (0)', '1': 'glioma (1)', '2': 'pituitary tumor (2)'}\n",
        "classes, counts = np.unique(labels,return_counts=True)\n",
        "plt.bar(classes,counts,tick_label=list(integer_to_class.values()))\n",
        "print(counts)"
      ],
      "metadata": {
        "id": "KzUpJ4q6xDuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test= train_test_split (images,masks,test_size=0.2, shuffle= True)\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "X4__cwVtxGSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape[0]"
      ],
      "metadata": {
        "id": "5XtMuMdqxL3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1=datalist[2][\"cjdata\"][\"image\"][()]\n",
        "plt.imshow(img1)\n",
        "print(int(datalist[2][\"cjdata\"][\"label\"][()])-1)"
      ],
      "metadata": {
        "id": "L3Byw1g0xQae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "\n",
        "for i in range(total_image):\n",
        "    img=datalist[i][\"cjdata\"][\"image\"][()]\n",
        "\n",
        "    if img.shape==(512,512):\n",
        "       img=np.expand_dims(img,axis=0)\n",
        "       x.append(img)\n",
        "\n",
        "       label=int(datalist[i][\"cjdata\"][\"label\"][()])-1\n",
        "       y.append(label)\n",
        "\n",
        "\n",
        "\n",
        "x=np.array(x).reshape(-1,512,512,1)\n",
        "y=np.array(y)\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "-FcPIKO5xgpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainx, testx, trainy, testy= train_test_split(x, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "print(trainx.shape)\n",
        "print(testx.shape)\n",
        "print(trainy.shape)\n",
        "print(testy.shape)"
      ],
      "metadata": {
        "id": "nKLl2jh4xkHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainx, testx, trainy, testy= train_test_split(x, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "print(trainx.shape)\n",
        "print(testx.shape)\n",
        "print(trainy.shape)\n",
        "print(testy.shape)"
      ],
      "metadata": {
        "id": "P4Qua29RxmDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14-Layer CNN"
      ],
      "metadata": {
        "id": "ucK08L-ExsF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(8, (5,5), activation='relu', input_shape=(512,512,1)),\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (5,5)),\n",
        "    tf.keras.layers.Conv2D(8, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (3,3)),\n",
        "    tf.keras.layers.Conv2D(8, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size = (2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "model1.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "r1=model1.fit(trainx,\n",
        "          trainy,\n",
        "          epochs=15,\n",
        "          batch_size=32,\n",
        "          verbose=1,\n",
        "          validation_data=(testx,testy),\n",
        "          shuffle=False\n",
        "          )"
      ],
      "metadata": {
        "id": "cneIL7rXxpMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('14 layers Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(0,5))\n",
        "ax1.plot(epoch_list, r1.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, r1.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 5, 4))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, r1.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, r1.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 5, 4))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "GITq0a6bxu91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model1.predict(testx)\n",
        "Y_pred = np.argmax(pred, 1)"
      ],
      "metadata": {
        "id": "pL1EKSl0x0Qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy Score :',accuracy_score(testy,Y_pred))\n",
        "print('Report : ')\n",
        "print(classification_report(testy,Y_pred))"
      ],
      "metadata": {
        "id": "ZD90ZTWwx1pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "ax= plt.subplot()\n",
        "cm=confusion_matrix(testy, Y_pred)\n",
        "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix');\n",
        "ax.xaxis.set_ticklabels(['Meningioma', 'Glioma', 'Pituitary']); ax.yaxis.set_ticklabels(['Meningioma', 'Glioma', 'Pituitary'])"
      ],
      "metadata": {
        "id": "SgT4ljEyx3J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23-layer"
      ],
      "metadata": {
        "id": "7Zp-S0C0x-R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ini_input=keras.Input(shape=(512,512,1),name=\"image\")\n",
        "\n",
        "x1=layers.Conv2D(64,(22,22),strides=2)(ini_input)\n",
        "x1=layers.MaxPooling2D((4,4))(x1)\n",
        "x1=layers.BatchNormalization()(x1)\n",
        "\n",
        "x2=layers.Conv2D(128,(11,11),strides=2,padding=\"same\")(x1)\n",
        "x2=layers.MaxPooling2D((2,2))(x2)\n",
        "x2=layers.BatchNormalization()(x2)\n",
        "\n",
        "x3=layers.Conv2D(256,(7,7),strides=2,padding=\"same\")(x2)\n",
        "x3=layers.MaxPooling2D((2,2))(x3)\n",
        "x3=layers.BatchNormalization()(x3)\n",
        "\n",
        "x4=layers.Conv2D(512,(3,3),strides=2,padding=\"same\")(x3)\n",
        "x4=layers.MaxPooling2D((2,2))(x4)\n",
        "x4=layers.BatchNormalization()(x4)\n",
        "\n",
        "x5=layers.GlobalAveragePooling2D()(x4)\n",
        "x5=layers.Activation(\"relu\")(x5)\n",
        "\n",
        "x6=layers.Dense(1024,\"relu\")(x5)\n",
        "x6=layers.BatchNormalization()(x6)\n",
        "\n",
        "x7=layers.Dense(512,\"relu\")(x6)\n",
        "x7=layers.BatchNormalization()(x7)\n",
        "\n",
        "x8=layers.Dense(256,\"relu\")(x7)\n",
        "x8=layers.BatchNormalization()(x8)\n",
        "\n",
        "x8=layers.Dropout(.2)(x8)\n",
        "x9=layers.Dense(3)(x5)\n",
        "pred=layers.Activation(\"softmax\")(x9)\n",
        "\n",
        "model=keras.Model(inputs=ini_input,outputs=pred)"
      ],
      "metadata": {
        "id": "ejZfmsqex6A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "24UeSCTsyF3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max'\n",
        ")"
      ],
      "metadata": {
        "id": "MW2FG8cOyI8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r=model.fit(trainx,\n",
        "          trainy,\n",
        "          epochs=50,\n",
        "          batch_size=32,\n",
        "          verbose=1,\n",
        "          validation_data=(testx,testy),\n",
        "          shuffle=False\n",
        "          )"
      ],
      "metadata": {
        "id": "kEZUcgJSyLxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epoch_list = list(range(0,50))\n",
        "ax1.plot(epoch_list, r.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epoch_list, r.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(np.arange(0, 50, 4))\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epoch_list, r.history['loss'], label='Train Loss')\n",
        "ax2.plot(epoch_list, r.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(np.arange(0, 50, 4))\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "metadata": {
        "id": "TdxPba7gyTNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(testx)\n",
        "Y_pred = np.argmax(pred, 1)\n",
        "\n",
        "Y_pred.shape\n",
        "\n",
        "testy.shape"
      ],
      "metadata": {
        "id": "01jAVEXnyUFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy Score :',accuracy_score(testy,Y_pred))\n",
        "print('Report : ')\n",
        "print(classification_report(testy,Y_pred))"
      ],
      "metadata": {
        "id": "55PJIKINybkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "print('Classification Report')\n",
        "target_names = ['Meningioma', 'Glioma', 'Pituitary']\n",
        "print(classification_report(testy, Y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "2Dz815sVyhcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "results = confusion_matrix(testy,Y_pred)\n",
        "print('Confusion Matrix :')\n",
        "print(results)\n",
        "print('Accuracy Score :',accuracy_score(testy,Y_pred))\n",
        "print('Report : ')\n",
        "print(classification_report(testy,Y_pred))\n",
        "\n",
        "sns.heatmap(results/np.sum(results), annot=True,\n",
        "            fmt='.2%', cmap='Blues')"
      ],
      "metadata": {
        "id": "i3jtlzoIykBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning"
      ],
      "metadata": {
        "id": "tq77GjiXzK9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet import ResNet50"
      ],
      "metadata": {
        "id": "FU0c0Ir4zFjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_Neural_Net= ResNet50(input_shape=(512,512,1), weights='imagenet', include_top=False)\n",
        "model=Sequential()\n",
        "model.add(base_Neural_Net)\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer = \"Adam\", metrics= ['accuracy'])\n",
        "hi=model.fit(trainx , trainy,validation_data=(testx,testy), batch_size=5, epochs=10)"
      ],
      "metadata": {
        "id": "730zQHwpzSXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(512,512,3))\n",
        "model = effnet.output\n",
        "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
        "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
        "model = tf.keras.layers.Dense(3,activation='softmax')(model)\n",
        "model = tf.keras.models.Model(inputs=effnet.input, outputs = model)"
      ],
      "metadata": {
        "id": "v2SVsWogzW3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "\n",
        "hist=model.fit(trainx , trainy,validation_data=(testx,testy), batch_size=5, epochs=2)"
      ],
      "metadata": {
        "id": "MVDWm9nk2fYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "conv = VGG16(input_shape= (512,512,1),weights='imagenet',include_top=False)\n",
        "\n",
        "\n",
        "for layer in conv.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = conv.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024,activation='relu')(x)\n",
        "x = Dense(1024,activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x=  Dropout(.2)(x)\n",
        "pred = Dense(3,activation='softmax')(x)\n",
        "model = Model(inputs = conv.input,outputs=pred)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history=model.fit(trainx , trainy,validation_data=(testx,testy), batch_size=5, epochs=10)"
      ],
      "metadata": {
        "id": "AStWWy6A2iUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Densenet"
      ],
      "metadata": {
        "id": "dxH5xl-12ywP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "\n",
        "conv =  DenseNet121(input_shape= (512,512,1),weights='imagenet',include_top=False)\n",
        "\n",
        "\n",
        "for layer in conv.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = conv.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024,activation='relu')(x)\n",
        "x = Dense(1024,activation='relu')(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x=  Dropout(.2)(x)\n",
        "pred = Dense(3,activation='softmax')(x)\n",
        "model = Model(inputs = conv.input,outputs=pred)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history=model.fit(trainx , trainy,validation_data=(testx,testy), batch_size=5, epochs=10)"
      ],
      "metadata": {
        "id": "aBYhhs9J20qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Squezenet"
      ],
      "metadata": {
        "id": "zf3RulUw4MMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# ---- SqueezeNet v1.1 backbone (include_top=False) ----\n",
        "def fire(x, s, e):\n",
        "    x = layers.Conv2D(s, 1, activation=\"relu\", padding=\"same\")(x)\n",
        "    e1 = layers.Conv2D(e, 1, activation=\"relu\", padding=\"same\")(x)\n",
        "    e3 = layers.Conv2D(e, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "    return layers.Concatenate()([e1, e3])\n",
        "\n",
        "def SqueezeNet_backbone(input_shape=(512, 512, 1)):\n",
        "    inp = layers.Input(shape=input_shape)\n",
        "    # map 1→3 channels so you can later load 3-ch weights if desired\n",
        "    x = layers.Conv2D(3, 1, padding=\"same\", name=\"gray_to_rgb\")(inp)\n",
        "\n",
        "    # v1.1 stem\n",
        "    x = layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"relu\", name=\"conv1\")(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool1\")(x)\n",
        "\n",
        "    # fire modules\n",
        "    x = fire(x, 16, 64)        # fire2\n",
        "    x = fire(x, 16, 64)        # fire3\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool3\")(x)\n",
        "\n",
        "    x = fire(x, 32, 128)       # fire4\n",
        "    x = fire(x, 32, 128)       # fire5\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool5\")(x)\n",
        "\n",
        "    x = fire(x, 48, 192)       # fire6\n",
        "    x = fire(x, 48, 192)       # fire7\n",
        "    x = fire(x, 64, 256)       # fire8\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool8\")(x)\n",
        "    x = fire(x, 64, 256)       # fire9\n",
        "\n",
        "    return Model(inp, x, name=\"squeezenet_v1_1_backbone\")\n",
        "\n",
        "\n",
        "inputs = layers.Input(shape=(512, 512, 1))\n",
        "conv = SqueezeNet_backbone(input_shape=(512, 512, 1))(inputs)\n",
        "\n",
        "for layer in conv.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(conv.output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "pred = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=pred)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(trainx, trainy,\n",
        "                    validation_data=(testx, testy),\n",
        "                    batch_size=5, epochs=10)\n"
      ],
      "metadata": {
        "id": "BWT0DC504Lcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alexnet"
      ],
      "metadata": {
        "id": "ZbpOsnWb43I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# ---- AlexNet backbone (include_top=False) ----\n",
        "def lrn(x):\n",
        "    return tf.nn.local_response_normalization(x)\n",
        "\n",
        "def AlexNet_backbone(input_shape=(512, 512, 1)):\n",
        "    inp = layers.Input(shape=input_shape, name=\"in_gray\")\n",
        "    x = layers.Conv2D(3, 1, padding=\"same\", name=\"gray_to_rgb\")(inp)  # 1→3\n",
        "\n",
        "    # conv1\n",
        "    x = layers.Conv2D(96, 11, strides=4, padding=\"same\", activation=\"relu\", name=\"conv1\")(x)\n",
        "    x = layers.Lambda(lrn, name=\"lrn1\")(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool1\")(x)\n",
        "\n",
        "    # conv2 (groups removed for simplicity)\n",
        "    x = layers.Conv2D(256, 5, padding=\"same\", activation=\"relu\", name=\"conv2\")(x)\n",
        "    x = layers.Lambda(lrn, name=\"lrn2\")(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool2\")(x)\n",
        "\n",
        "    # conv3–5\n",
        "    x = layers.Conv2D(384, 3, padding=\"same\", activation=\"relu\", name=\"conv3\")(x)\n",
        "    x = layers.Conv2D(384, 3, padding=\"same\", activation=\"relu\", name=\"conv4\")(x)\n",
        "    x = layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\", name=\"conv5\")(x)\n",
        "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\", name=\"pool5\")(x)\n",
        "\n",
        "    return Model(inp, x, name=\"alexnet_backbone\")\n",
        "\n",
        "# ---- Build your classifier on top (same head as before) ----\n",
        "inputs = layers.Input(shape=(512, 512, 1))\n",
        "conv = AlexNet_backbone(input_shape=(512, 512, 1))(inputs)\n",
        "\n",
        "for layer in conv.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(conv.output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "pred = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=pred)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "history = model.fit(trainx, trainy,\n",
        "                    validation_data=(testx, testy),\n",
        "                    batch_size=5, epochs=10)\n"
      ],
      "metadata": {
        "id": "WZMK4jeG44PG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}